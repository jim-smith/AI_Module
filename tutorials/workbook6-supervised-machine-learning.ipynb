{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "TODO change to the  code from lectures and change  progression:\n",
    "    <ol> \n",
    "        <li> Activity 1: the data </li>\n",
    "         <ul> \n",
    "             <li>Iris data using the actua llabels then the visualisation from last week</li>\n",
    "            <li> student marks data using visualiations from last week </li>    \n",
    "            <li> MCQ's to confirm that one class is seperable, the others are not </li>\n",
    "        </ul>\n",
    "    <li>  Activity 2: Take my 1-NN code from the lectures, and the k-NN pseudocode and implement kNN for iris and studentMarks</li>\n",
    "        <ul>\n",
    "          <li> Sanity check: create a new classifier using the sklearn class and verify their results are in the same ball park (not statistically significantly different?)  </li>\n",
    "          <li> provide the code that plots decision surfaces, look at effect of changing K </li>\n",
    "        </ul>\n",
    "        \n",
    "    <li> Actvity 3: repeat for decision trees using code from lectures.</li>\n",
    "        <ul> \n",
    "            <li>Task is to examine effect of changing max depth and number per split on (i) trees and. (ii) test accuracy</li>\n",
    "            <li> needs MCQ to test findings  and understnading - max-depth limits every subtree,  min-spolit limiits unpopulated subtrees</li>\n",
    "        </ul>\n",
    "    </ol></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "TODO change to the  code from lectures and change  progression:\n",
    "    <ol> \n",
    "    <li>  They put the Iris data into the visualisations they made last week but this time using the class labels (provbide rough code ion case they didn;t do last week but encourage thme to use their own)</li>\n",
    "        <li> MCQ's to confirm that one class is seperable, the others are not </li>\n",
    "    <li>  Take my 1-NN code from the lectures, and the k-NN pseudocode and implement kNN for iris</li>\n",
    "    <li> Sanity check: create a nre wclassifier using the sklearn class and verify their results are in the same ball park (not statistically significantly different?)  </li>\n",
    "<li> Wrap-up discussion about comparing algorithms and when it is safe to say methodX is better than method Y. Realte back to disc ussinos in new second week workbook, topical real world - relate to comparison of vaccines, or different treatments for covid\n",
    "    </ol></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbook 6: Supervised Machine Learning\n",
    "\n",
    "## Description and aims\n",
    "\n",
    "This tutorial is designed to give you your first experience of machine learning in practice by implementing a simple nearest-neighbour classifier.\n",
    "\n",
    "The learning outcomes are:\n",
    "- experience of implementing the K Nearest Neighbours classification algorithm\n",
    "- experience of using the sklearn DecisionTree classification algorithm\n",
    "-  experience of working through different preprocessing steps to try and improve the performance of your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 1: Getting to know your data: \n",
    "\n",
    "We will start by importing and visualising the two datasets used as examples in the lecture: students marks,  and Iris\n",
    "### You should already have uploaded the data and figures from the lecture materials folder - if not, do so now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_scatterplot_matrix(X,y,featureNames,title=None):\n",
    "    f = X.shape[1]\n",
    "    if(len(y) != X.shape[0]):\n",
    "        print(\"Error,   the y array  must have the same length as there are rows in X\")\n",
    "        return\n",
    "    fig, ax = plt.subplots(f,f,figsize=(12,12))\n",
    "    plt.set_cmap('jet')\n",
    "    for feature1 in range(f):\n",
    "        ax[feature1,0].set_ylabel( featureNames[feature1])\n",
    "        ax[0,feature1].set_xlabel( featureNames[feature1])\n",
    "        ax[0,feature1].xaxis.set_label_position('top') \n",
    "        for feature2 in range(f):\n",
    "            xdata = X[:,feature1]\n",
    "            ydata = X[:,feature2]\n",
    "            ax[feature1, feature2].scatter(xdata,ydata,c=y)\n",
    "    if title != None:\n",
    "        fig.suptitle(title,fontsize=16,y=0.925)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Student marks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grades= np.genfromtxt(\"../lectures/data/assessment-grades-2features.csv\", delimiter= ',',skip_header=1)\n",
    "\n",
    "featureNames=(\"exam\", \"CW_mean\")\n",
    "nStudents = grades.shape[0]\n",
    "\n",
    "outcomes= (\"Pass\",\"Resit Exam\", \"Resit Coursework\",\"Resit Both\")\n",
    "simpleoutcomes= (\"pass\",\"resit\")\n",
    "\n",
    "# make target labels\n",
    "result = np.empty(nStudents, dtype=np.int8)\n",
    "\n",
    "for row in range (nStudents):\n",
    "    exam = grades[row][0]\n",
    "    cw   = grades[row][1]\n",
    "    if (exam>=35 and cw>=35 and (exam +cw >=80) ):\n",
    "        result[row] = 0 # PASS \n",
    "\n",
    "    elif ( cw>=40 and exam < 40):\n",
    "        result[row] = 1 #resit just exam \n",
    "    elif ( cw<40 and exam>=40):\n",
    "        result[row]= 2 # resit just coursework\n",
    "    else:\n",
    "        result[row] = 3  # resit both\n",
    "        \n",
    "simpleResult = np.where(result<1,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easiest to split the data into 4/2 subgroups ot plot the outomes /simplified outcomes\n",
    "\n",
    "passStudents = np.empty((0,2))\n",
    "resitCWStudents = np.empty((0,2))\n",
    "resitExamStudents = np.empty((0,2))\n",
    "resitBothStudents = np.empty((0,2))\n",
    "\n",
    "for student in range (nStudents):\n",
    "    if (result[student]==0):\n",
    "        passStudents = np.vstack( (passStudents,grades[student]) )\n",
    "    elif (result[student]==1):\n",
    "        resitExamStudents = np.vstack( (resitExamStudents,grades[student]) )\n",
    "    elif (result[student]==2):\n",
    "        resitCWStudents = np.vstack( (resitCWStudents,grades[student]) )\n",
    "    else:\n",
    "        resitBothStudents = np.vstack( (resitBothStudents,grades[student]) )\n",
    "simpleResitStudents = np.vstack( (resitExamStudents,resitCWStudents,resitBothStudents))\n",
    "\n",
    "print(passStudents.shape)\n",
    "print(resitExamStudents.shape)\n",
    "print(resitCWStudents.shape)\n",
    "print(resitBothStudents.shape)\n",
    "print(simpleResitStudents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(14,5))\n",
    "plt.xlabel(\"Exam\")\n",
    "plt.ylabel(\"Coursework\")\n",
    "ax[0].set_title(\"Outcomes\")\n",
    "ax[1].set_title(\"Simplified Outcomes\")\n",
    "\n",
    "ax[0].scatter(passStudents[:,0],passStudents[:,1],label = \"Pass\" )\n",
    "ax[0].scatter(resitExamStudents[:,0],resitExamStudents[:,1],label = \"Resit Exam\" )\n",
    "ax[0].scatter(resitCWStudents[:,0],resitCWStudents[:,1],label = \"Resit CW\" )\n",
    "ax[0].scatter(resitBothStudents[:,0],resitBothStudents[:,1],label = \"Resit Both\" )\n",
    "ax[1].scatter(passStudents[:,0],passStudents[:,1],label = \"Resit\" )\n",
    "ax[1].scatter(simpleResitStudents[:,0],simpleResitStudents[:,1],label = \"Pass\" )\n",
    "\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[1].legend(loc='lower right') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2:  Iris flowers <img src=\"../lectures/figures/ML/Iris-image.png\" style=\"float:right\">\n",
    "- classic Machine Learning Data set\n",
    "- 4 measurements: sepal and petal width and length\n",
    "- 50 examples  from each 3 sub-species for iris flowers\n",
    "- three class problem:\n",
    " - so for some types of algorithm have to decide whether to make  \n",
    "   a 3-way classifier or nested 1-vs-rest classifers\n",
    "- most ML classifiers can get over 90%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "irisX,irisy = sklearn.datasets.load_iris(return_X_y=True)\n",
    "columnLabels= (\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\")\n",
    "title=\"Scatterplots of 2D slices through the 4D Iris data\"\n",
    "show_scatterplot_matrix(irisX,irisy,columnLabels,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2: Implementing K-Nearest Neighbours\n",
    "Below is the pseudocodefor the K-nearest Neighbours algorithm.\n",
    "Make sure you understand this,   then read the cell below which is my implentation for K=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode for KNearest Neighbours\n",
    "**init()**  :  \n",
    "Specify a distance metric d(i,j) for any two items *i* and *j*     \n",
    "  e.g. Euclidean (continuous variables) or Hamming (categorical)\n",
    "\n",
    "**fit(trainingData)** :  \n",
    "Just store a local copy of the training data as two arrays:  \n",
    "X_train of shape (numTrainingItems , numFeatures),  \n",
    "y_train of shape( numTrainingItems)\n",
    "  \n",
    "**predict(newItems)** :  \n",
    "*Step 1:   Make 2D array distances of shape (num_newItems , numTrainingItems)*   \n",
    "FOREACH newItem i  \n",
    "...FOREACH trainingitem j  \n",
    ".....SET distances [i] [j] = d (i,j) \n",
    "\n",
    "*Step 2: Get labels of the k nearest neighbours*  \n",
    "FOREACH newItem i  \n",
    "...Find the *k* columns for row i with the smallest values  \n",
    "...Get the corresponding *k* labels from y_train  \n",
    "\n",
    "*Step 3: Store majority vote in a  1D array y_pred of size (numToPredict)*   \n",
    "FOREACH newItem i  \n",
    "...FOREACH label m  \n",
    "......Count votes amongst the k Nearest neightbour of i  \n",
    "...... SET y_pred[i] = value of m with highest count\n",
    " \n",
    "RETURN y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for K = 1 \n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "class simple_1NN:\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.numExemplars = X.shape[0]\n",
    "        self.numFeatures = X.shape[1]\n",
    "        self.modelX = X\n",
    "        self.modelY = y\n",
    "        \n",
    "    def predict(self,newItems):\n",
    "        numToPredict = newItems.shape[0]\n",
    "        yPred = np.zeros((numToPredict,1))\n",
    "        \n",
    "        # measure distances - creates an array with numToPredict rows and num_trainItems columns\n",
    "        dist = euclidean_distances(newItems,self.modelX)\n",
    "\n",
    "        #make predictions: This is K=1, TO DO- in your own time extend to work with K>1\n",
    "        for item in range(numToPredict):\n",
    "            closest = np.argmin(dist, axis=1) \n",
    "            yPred[item] = self.modelY [ closest[item]]\n",
    "        \n",
    "        return yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2.1 Run the code provided for K=1 with the two datasets and make sure you understand the outputs and how they are produced\n",
    "- for the marks dataset this creates a plot to show a decision surface\n",
    "- for the  iris data set this uses a confision matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Marks dataset - illustrating a 2D Decision surface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and prettify the plot\n",
    "cmap=\"Set3\"\n",
    "fig,ax= plt.subplots(figsize=(8, 8))\n",
    "ax.set_title(\"1 nearest neighbours, simplified results\")\n",
    "ax.set_xlabel(featureNames[0])\n",
    "ax.set_ylabel(featureNames[1])\n",
    "\n",
    "#define a grid we use to plot the decision boundaries\n",
    "h = 2.0    \n",
    "x_min, x_max = -10,110\n",
    "y_min, y_max = -10,110\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "# create and train the classifier\n",
    "myKNN = simple_1NN()\n",
    "myKNN.fit(grades,simpleResult) \n",
    "\n",
    "#predict and plotfor evey point on the grid\n",
    "Z = myKNN.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, Z,cmap=cmap)\n",
    "\n",
    "# Plot also the training points\n",
    "ax.scatter(x=grades[:,0 ],y= grades[:, 1], c=simpleResult.astype(float), alpha=1.0, cmap=cmap, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Iris dataset - illustrating a confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train/test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "irisX,irisy = load_iris(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(irisX, irisy, test_size=0.33,stratify=irisy)\n",
    "\n",
    "\n",
    "model = simple_1NN()\n",
    "model.fit(X_train,y_train)\n",
    "ypred = model.predict(X_test)\n",
    "confusionMatrix = np.zeros((3,3),int)\n",
    "for i in range(50):\n",
    "    actual = int(y_test[i])\n",
    "    predicted = int(ypred[i])\n",
    "    confusionMatrix[actual][predicted] += 1\n",
    "print(confusionMatrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2.2 (stretch): edit the code in the cells above to produce:\n",
    "- a confusion matrix for the marks dataset\n",
    "- a decision surface for the four-class version of the marks dataset  \n",
    "  i.e. using the labels held in the array \"results\" instead of \"simplifiedResults\"\n",
    "- a decision surface for the Iris Data  \n",
    "  you will need to take just two features - you could use the first two, or the best two you identified last week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2.3: Create your own implementation of K-Nearest Neighbours\n",
    "Using the code above,  extend it to use the votes from K>1 neighbours.\n",
    "\n",
    "These are the lines you will need to change:\n",
    "````  \n",
    "#make predictions: This is K=1, TO DO- in your own time extend to work with K>1\n",
    "        for item in range(numToPredict):\n",
    "            closest = np.argmin(dist, axis=1) \n",
    "            yPred[item] = self.modelY [ closest[item]]\n",
    "```` \n",
    "\n",
    "Some hints: \n",
    "- Make sure you change the class name to something appropriate\n",
    "- You should  set (and store) the value of K in the constructor method\n",
    "- If I have an array of myDist of (say, for simplicity) five values,  \n",
    "   and I want to resort them by size, keep track of the item ids  \n",
    "   so i can find the K with the smallest values in the original array. \n",
    "   I can do it using the code below, which:\n",
    "   - creates a 2d array holding each value and its index in the original array\n",
    "   - then makes a new array which is the 'unSorted' 2d array, but sorted by the values in the first olumn ([0])\n",
    "   - then looks in the second column (which holds the indexes) for the first K rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cells just contains some hints about how to prodice a sorted array\n",
    "myDist = np.array([4,7,1,3,9])\n",
    "\n",
    "myUnsortedArray = np.empty((5,2))\n",
    "print(myUnsortedArray.shape)\n",
    "for row in range (5):\n",
    "    myUnsortedArray [row][0] = myDist[row]\n",
    "    myUnsortedArray [row][1] = row\n",
    "print('myUnsortedArray contents before sorting')\n",
    "print(myUnsortedArray)\n",
    "\n",
    "ind = np.argsort( myUnsortedArray[:,0] );\n",
    "mySortedArray = myUnsortedArray[ind]\n",
    "\n",
    "\n",
    "print('mySortedArray contents after sorting')\n",
    "print(mySortedArray)\n",
    "\n",
    "print('Last week we learned about slicing- we will now use slicing to pull out all rows but just specific columns')\n",
    "print(' the values in array myDist in ascending order are: {}'.format(mySortedArray[:,0]))\n",
    "print(' the positions those values were in, again by ascending order of value are : {}'.format(mySortedArray[:,1]))\n",
    "print('Now remember you do not have to choose every row ... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your KNN class code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2.4: Test your impementation on the two example datasets\n",
    "- use the toolbar to copy and paste the two cells from activity 2.1 below here\n",
    "- then edit them so that they create and use objects of your new class, instead of the class simple_1NN\n",
    "\n",
    "- start with K=1 - this should produce the same results as you got in activity 2.1\n",
    "- then try with K = {3,5,7}\n",
    "- what happens to the accuracy?\n",
    "- what happens to the decision surface?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 3: Decision Trees\n",
    "\n",
    "\n",
    "The ainm of this activity is for you to experiment with what happens when you change three parameters that affect how big and complex the tree is allowed to get.\n",
    "- max_depth\n",
    "- min_samples_split, (default value is 2)\n",
    "- min_samples_leaf, (default value is 1)\n",
    "\n",
    "Experiment with the data sets below to see if you can work out what each of these parameters does, and how it affects the tree \n",
    "\n",
    "- Each time you run the  cell below, it will give you a different train-test split of the Iris data.\n",
    "  Does this affect what tree you get?\n",
    "  \n",
    "- Is there a combination of values that means you consistently get similar trees?\n",
    "- What is a good way of judgiung 'similarity?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "\n",
    "# load iris dataset and split into train:test\n",
    "iris = sklearn.datasets.load_iris()\n",
    "irisX = iris.data\n",
    "irisy = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(irisX, irisy, test_size=0.33,stratify=irisy)\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1234, max_depth=None,min_samples_split=2,min_samples_leaf=1)\n",
    "model.fit(X_train,y_train)\n",
    "ypred = model.predict(X_test)\n",
    "confusionMatrix = np.zeros((3,3),int)\n",
    "for i in range(50):\n",
    "    actual = int(y_test[i])\n",
    "    predicted = int(ypred[i])\n",
    "    confusionMatrix[actual][predicted] += 1\n",
    "print(confusionMatrix)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "_ = tree.plot_tree(model, \n",
    "                   feature_names=iris.feature_names,  \n",
    "                   class_names=iris.target_names,\n",
    "                   filled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> Please save your work (click the save icon) then shutdown the notebook when you have finished with this tutorial (menu->file->close and shutdown notebook</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> Remember to download and save your work if you are not running this notebook locally.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
