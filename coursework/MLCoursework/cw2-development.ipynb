{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register a 'cell magic' to let us save the code in a cell to file and run the python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell)\n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import classes from modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from LearnedRuleModel import LearnedRuleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next cell contains your class definition\n",
    "### The first line saves the python code   to file every time the cell is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run GreedyRuleInductionModel.py\n",
    "\n",
    "\n",
    "\n",
    "class GreedyRuleInductionModel(LearnedRuleModel):\n",
    "    \n",
    "    def __init__(self,maxRules=10, increments=25):\n",
    "        # call the init function for the super class\n",
    "        # and inherit all the other methods\n",
    "        super().__init__(maxRules=maxRules, increments=increments)\n",
    "\n",
    "\n",
    "        \n",
    "    def fit( self,train_X,train_y):\n",
    "      #  Preprocess (trainingset)  \n",
    "      # store the set of different labels - don't assume theyare 0,12,2 etc\n",
    "        self.labels = np.unique(train_y)\n",
    "\n",
    "        # remember how many features there are describing each trainig case\n",
    "        self.numFeatures= train_X.shape[1]\n",
    "        \n",
    "        # preprocess the data to compute the set of thresholds  to be used in rules\n",
    "        # there are self.numThresholds of these for each feature\n",
    "        self.CalculatePossibleThresholds(train_X)\n",
    "  \n",
    "        # now to learn from the data\n",
    "        \n",
    "        ###== YOUR CODE HERE====####\n",
    "            ## I suggest you copy in the pseudocode from the lecture then code to that\n",
    "            ## some of the lines in that pseudocode have been covered above\n",
    "            ## and some are covered in the init() method\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def predict(self, examples):\n",
    "        ypred = np.zeros(examples.shape[0],dtype=np.uint)\n",
    " \n",
    "   \n",
    "  \n",
    "        ###== YOUR CODE HERE====####\n",
    "            ## I suggest you start by setting everything in ypred to a valid default value\n",
    "            ## i.e. something from the list self.labels\n",
    "            \n",
    "            ## then you will find it useful to look at the score() method in the super class\n",
    "            ## to see how you can try to match rules from your ruleset  for each  test instance in turn\n",
    "        \n",
    "        return ypred\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the iris data and split it into train/test\n",
    "### This is just for development, your code will not be tested on the iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import train_test_split \n",
    "\n",
    "#the iris data\n",
    "from sklearn.datasets import load_iris\n",
    "irisX,irisy = load_iris(return_X_y = True)\n",
    "iris_train_X, iris_test_X, iris_train_y, iris_test_y = train_test_split(irisX,irisy, test_size=0.33, stratify=irisy )\n",
    "\n",
    "irisLabels=['Setosa','Versicolor','Virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now create an object of my class and test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 4 0]\n",
      " [0 2 4 2]]\n",
      "\tThe Learned Model is: \n",
      "\tIF feature 0 < 4.876 THEN label= 0\n",
      "\tELSE IF feature 0 > 4.876 THEN label= 2\n"
     ]
    }
   ],
   "source": [
    "myClassifier = GreedyRuleInductionModel(maxRules=5)\n",
    "myClassifier.fit(iris_train_X,iris_train_y)\n",
    "\n",
    "#hard coding in some rules\n",
    "myClassifier.ruleSet[0] = [0,0,4,0]\n",
    "myClassifier.ruleSet[1] = [0, 2, 4, 2]\n",
    "myClassifier.numRules=2\n",
    "\n",
    "print(myClassifier.GetRuleSet())\n",
    "\n",
    "myClassifier.PrintRuleSet()\n",
    "\n",
    "predictions = myClassifier.predict(iris_test_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets look at what it predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### lets print out a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted->   Setosa  Versicolor  Virginica\n",
      "Actual \n",
      "Setosa           17        0        0\n",
      "Versicolor       16        0        0\n",
      "Virginica        17        0        0\n"
     ]
    }
   ],
   "source": [
    "# this bit of code prints a simple confusion matrix showing how the predicted labels correspond to the 'real' ones\n",
    "\n",
    "irisLabels=['Setosa','Versicolor','Virginica']\n",
    "confusion = np.zeros((3,3))\n",
    "for row in range (predictions.shape[0]):\n",
    "    actual = iris_test_y[row]\n",
    "    predicted = np.argmax(predictions[row])\n",
    "    confusion [actual] [predicted] += 1\n",
    "\n",
    "print( '\\nPredicted->   Setosa  Versicolor  Virginica')\n",
    "print( 'Actual ')\n",
    "for i in range(3):\n",
    "    print( '{:<10}       {:2.0f}       {:2.0f}       {:2.0f}'.format(irisLabels[i], confusion[i][0], confusion[i][1],confusion[i][2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
