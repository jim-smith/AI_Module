{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking system for second coursework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# this is the only import you are allowed in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABSGreedyRuleInductionModel:\n",
    "    \n",
    "    def __init__(self, maxRules=5, increments=100):\n",
    "        # you probably won't need to change this\n",
    "        # empty array to hold model (ruleset)\n",
    "        self._maxRules= maxRules\n",
    "        self._model = np.empty((self._maxRules,4))\n",
    "        self._numRules=0\n",
    "        # number of threshold values to consider for each feature\n",
    "        self._increments=increments\n",
    "        #empty model makes no correct or incorrect predictions\n",
    "        self.score=0\n",
    "    \n",
    "    def GetModel(self):\n",
    "        return self._model[:self._numRules,: ]\n",
    "        \n",
    "    def fit(self, train_X,train_y):\n",
    "        # your code here\n",
    "        \n",
    "        # when you finish your set of rules should be stored in self._model\n",
    "        # and the number of rules in self._numRules\n",
    "        pass\n",
    "    \n",
    "    def predict(self,examples):\n",
    "        ypred = np.zeros(examples.shape[0])\n",
    "        # your code here\n",
    "        return ypred       \n",
    "    \n",
    "    def preprocess(self, data):\n",
    "        # your code goes here\n",
    "        #to calculate the set of threshold values to loop over for each feature\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyRuleInductionModel:\n",
    "    \n",
    "    def __init__(self,maxRules=5, increments=10):\n",
    " \n",
    "        #read some user-configurablew paramerers\n",
    "        ## maximum size of ruleset that is our model\n",
    "        self.maxRules= maxRules\n",
    "        ## number of threshold values to consider for each feature\n",
    "        self.numThresholds=increments\n",
    "        \n",
    "        # initialise currentModel to be an empty array with no rules that scores 0\n",
    "        self.model = np.empty((self.maxRules,4),dtype=np.uint)\n",
    "        self.numRules=0\n",
    "        self.score=0\n",
    "\n",
    "    \n",
    "    def GetModel(self):\n",
    "        return self.model[:self.numRules,: ]\n",
    "        \n",
    "    def fit( self,train_X,train_y):\n",
    "         # store the set of different labels - don;t assume theyare 0,12,2 etc\n",
    "        self.labels = np.unique(train_y)\n",
    "\n",
    "        # preprocess the data to compute threasholds to be used in rules\n",
    "        self.preprocess(train_X)\n",
    "        numTrItems=train_X.shape[0]\n",
    "\n",
    "        #WHILE (currentModel.score<trainingsetSize) DO \n",
    "        while (self.score<numTrItems and self.numRules<self.maxRules):\n",
    "            print(\"Adding to model with {} rules which score {}\".format(self.numRules,self.score))\n",
    "            # SET bestchild = emptyModel\n",
    "            bestChild= self.model.copy()\n",
    "            bestChildScore=self.score\n",
    "            \n",
    "            #FOR newRule in  (all_possible_rules)\n",
    "            for feature in range(self.numFeatures):\n",
    "                for operator in range (3):\n",
    "                    for threshold in range (self.numThresholds):\n",
    "                        for label in range(len(self.labels)):\n",
    "                            newRule= np.array ( [feature,operator,threshold,label])\n",
    "                            #   SET newModel = COPY(currentModel)\n",
    "                            newModel = self.model.copy()\n",
    "                            ##  SET newModel = ADDRULE (newModel, newRule)\n",
    "                            newModel[self.numRules]= newRule\n",
    "                            #  SET score = SCORE(newModel)\n",
    "                            newScore = self.Score(newModel, self.numRules+1,train_X,train_y)\n",
    "                            #  IF (newModel.score > bestChild.score)\n",
    "                            if (newScore>bestChildScore):\n",
    "                                #SET bestChild= COPY(newModel)\n",
    "                                bestChild = newModel.copy()\n",
    "                                bestChildScore = newScore\n",
    "                                #print(\"new best rule for this iteration classifies {}\".format(bestChildScore))\n",
    "\n",
    "            #IF (bestChild.score > currentModel.score)\n",
    "            if (bestChildScore > self.score):\n",
    "                #SET currentModel=COPY (bestChild)\n",
    "                self.model = bestChild.copy()\n",
    "                self.numRules += 1\n",
    "                self.score = bestChildScore\n",
    "            else:\n",
    "                print(\"exiting training loop becuase no improving rule could be found\")\n",
    "                break\n",
    "\n",
    "                \n",
    "        print(\"Model has {} rules and a training set accuracy of {}\".format(self.numRules,(100*self.score/numTrItems)))\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, examples):\n",
    "        ypred = np.zeros(examples.shape[0],dtype=np.uint)\n",
    "        for item in range (examples.shape[0]):\n",
    "            prediction = -1 # i'm going ot use -1 to denote \"NO_PREDICTION\"\n",
    "            for currentRule in range (self.numRules):\n",
    "                if ( self.ItemMatchesRule(self.model[currentRule], examples[item] )==True):\n",
    "                    prediction = self.model[currentRule][3]\n",
    "                    break\n",
    "            ypred[item]= self.labels[prediction]\n",
    "        return ypred\n",
    "    \n",
    "    \n",
    "    def preprocess(self, data):\n",
    "        # your code goes here\n",
    "        #to calculate the set of threshold values to loop over for each feature\n",
    "        numItems = data.shape[0]\n",
    "        self.numFeatures= data.shape[1]\n",
    "        self.thresholds = np.empty((self.numFeatures, self.numThresholds))\n",
    "        maxValues = np.max(data,axis=0)\n",
    "        minValues = np.min( data, axis=0)\n",
    "        for feat in range (self.numFeatures):\n",
    "            thisFeatureIncrement = (maxValues[feat] - minValues[feat] )/self.numThresholds\n",
    "            for thresh in range ( self.numThresholds):\n",
    "                self.thresholds[feat][thresh] = minValues[feat] + thresh * thisFeatureIncrement\n",
    "\n",
    "        \n",
    "    def ItemMatchesRule( self,rule, item):\n",
    "\n",
    "        if len(rule) != 4:\n",
    "            print(\"error in ItemMatchesRule, rule must contain exactly four values\")\n",
    "            return False\n",
    "        feature = int(rule[0])\n",
    "        if( feature <0 or feature> self.numFeatures):\n",
    "            print('invalid feature id encountered')\n",
    "            return False\n",
    "        operator = int(rule[1])\n",
    "        if( operator <0 or operator>2):\n",
    "            print('invalid operator id encountered')\n",
    "            return False\n",
    "        thresholdId = int(rule[2])\n",
    "        if( thresholdId <0 or thresholdId>= self.numThresholds):\n",
    "            print('invalid threshold index encountered')\n",
    "            return False\n",
    " \n",
    "\n",
    "        threshold = self.thresholds[feature][thresholdId]\n",
    "        \n",
    "        #print('rule is feature {} operator {} thrshold {}'.format(feature,operator,threshold))\n",
    "        #print('item is {}'.format(item))\n",
    "        \n",
    "        if( (operator==0) and  (item [feature] < threshold) ):\n",
    "            return(True)\n",
    "        elif (operator ==1 and  ( item [feature] == threshold) ):\n",
    "            return True\n",
    "        elif ( (operator ==2) and ( item [feature]> threshold)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def Score( self,model, numRules, dataset_X,dataset_y):\n",
    "        numToPredict = dataset_X.shape[0]\n",
    "        numCorrect=0\n",
    "        for item in range( numToPredict):\n",
    "            prediction = -1 # i'm going ot use -1 to denote \"NO_PREDICTION\"\n",
    "            for currentRule in range (numRules):\n",
    "                if ( self.ItemMatchesRule(model[currentRule], dataset_X[item] )==True):\n",
    "                    prediction = self.labels[model[currentRule][3]]\n",
    "                    break\n",
    "            if (prediction>=0 and  prediction != dataset_y[item] ):\n",
    "                numCorrect = -1\n",
    "                break\n",
    "            elif (prediction == dataset_y[item]):\n",
    "                numCorrect +=1\n",
    "        return numCorrect\n",
    "            \n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAlgorithmOnDataset(X_train, y_train,X_test,y_test):\n",
    "    \n",
    "    myModel = GreedyRuleInductionModel(maxRules=5)\n",
    "\n",
    "    myModel.fit(X_train,y_train)\n",
    "    #print(\"learned model is {}\".format(myModel.GetModel()))\n",
    "\n",
    "    ypred = myModel.predict(X_test)\n",
    "\n",
    "    confusionMatrix = np.zeros((4,4),np.uint)\n",
    "    accuracy = 0.0\n",
    "    for i in range(len(y_test)):\n",
    "        actual = int(y_test[i])\n",
    "        predicted = int(ypred[i])\n",
    "        confusionMatrix[actual][predicted] += 1\n",
    "        if(actual==predicted):\n",
    "            accuracy += 1.0\n",
    "    accuracy = accuracy*100/len(y_test)\n",
    "    print(\" accuracy on this dataset is {}%\".format(accuracy))\n",
    "    print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to model with 0 rules which score 0\n",
      "Adding to model with 1 rules which score 33\n",
      "Adding to model with 2 rules which score 52\n",
      "Adding to model with 3 rules which score 70\n",
      "Adding to model with 4 rules which score 73\n",
      " accuracy on this dataset is 84.0%\n",
      "[[17  0  0  0]\n",
      " [ 0  8  8  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  0  0  0]]\n",
      "Adding to model with 0 rules which score 0\n",
      "Adding to model with 1 rules which score 33\n",
      "Adding to model with 2 rules which score 56\n",
      "Adding to model with 3 rules which score 66\n",
      "Adding to model with 4 rules which score 74\n",
      " accuracy on this dataset is 86.0%\n",
      "[[17  0  0  0]\n",
      " [ 0 11  6  0]\n",
      " [ 0  1 15  0]\n",
      " [ 0  0  0  0]]\n",
      "Adding to model with 0 rules which score 0\n",
      "Adding to model with 1 rules which score 33\n",
      "Adding to model with 2 rules which score 52\n",
      "Adding to model with 3 rules which score 69\n",
      "Adding to model with 4 rules which score 73\n",
      " accuracy on this dataset is 84.0%\n",
      "[[17  0  0  0]\n",
      " [ 0  8  8  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  0  0  0]]\n",
      "Adding to model with 0 rules which score 0\n",
      "Adding to model with 1 rules which score 33\n",
      "Adding to model with 2 rules which score 56\n",
      "Adding to model with 3 rules which score 79\n",
      "Adding to model with 4 rules which score 82\n",
      " accuracy on this dataset is 90.0%\n",
      "[[17  0  0  0]\n",
      " [ 0 13  3  0]\n",
      " [ 0  2 15  0]\n",
      " [ 0  0  0  0]]\n",
      "Adding to model with 0 rules which score 0\n",
      "Adding to model with 1 rules which score 33\n",
      "Adding to model with 2 rules which score 58\n",
      "Adding to model with 3 rules which score 81\n",
      "Adding to model with 4 rules which score 83\n",
      " accuracy on this dataset is 90.0%\n",
      "[[17  0  0  0]\n",
      " [ 0 13  3  0]\n",
      " [ 0  2 15  0]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# simple training on the iris data\n",
    "\n",
    "# make train/test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "irisX,irisy = load_iris(return_X_y = True)\n",
    "irisy = irisy \n",
    "\n",
    "for repetition in range (5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(irisX, irisy, test_size=0.33,stratify=irisy)\n",
    "\n",
    "    TestAlgorithmOnDataset(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
