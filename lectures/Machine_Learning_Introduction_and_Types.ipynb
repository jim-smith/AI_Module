{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Artificial Intelligence Topic 2 Machine Learning\n",
    "\n",
    "## Week 5: Introduction, Ethics and types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Week:\n",
    "###  Background\n",
    "- What is ML: recap\n",
    "- Types of ML\n",
    "- Ethical Considerations\n",
    "- Creating and Using Data\n",
    "\n",
    "###  Types of Machine Learning\n",
    "- Unsupervised Learning\n",
    " - K-Means as an example\n",
    "- Reinforcement Learning\n",
    "\n",
    "\n",
    "### Next few weeks: \n",
    "- Supervised Machine Learning, \n",
    "- Artificial Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap:<img style=\"float:right\" width=300 src=\"./figures/ML/basic-model-fitting.png\">\n",
    "- Machine Learning is:\n",
    " - the application of inductive logic to a dataset\n",
    " -  to create useful predictive models.  \n",
    " - So it is about solving  modelling problems\n",
    " \n",
    "\n",
    "- In week 1 we learned that problem solving is what you do when one of  \n",
    "  Input > Model –> Output     is missing\n",
    "- In the last topic we looked at how we **manually** create models encoding human expertise\n",
    "- Machine Learning is about how you **automatically** create models  from data (inputs and outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So it’s all about the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Yes!\n",
    "\n",
    "The aim is to build ML systems that can be used to do things when data or scenarios arise. \n",
    "\n",
    "So we need data to: \n",
    "- train them on,  \n",
    "- choose between models, \n",
    "- Know (estimate) how well they are going to do when we start using them\n",
    "\n",
    "We may not always have an output for every input \n",
    "- Because they’re not possible to capture\n",
    "  - e.g. data from scientific experiments such as genomics, astrophysics,...\n",
    "- Because sometimes we have to wait a while e.g.,\n",
    "  - game playing\n",
    "  - finding human volunteers to label images/ caption videos,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of Machine Learning\n",
    "Type | Inputs | Outputs | Feedback | What drives search? | Examples\n",
    "-----|--------|---------|----------------|---------------------|---------------------\n",
    "**Supervised** | Data |Predictions for each case | Correct labels | Accuracy of predictions made | **Recognition**  speech, images, actions, **Forecasting**\n",
    "**Reinforcement**| Scenarios | Actions to take in different states | Periodic Rewards | Expected future feedback | Learning game strategy\n",
    "**Unsupervised** | Data| Groupings of similar items | None | Statistics about cluster *coherence* and separation | Recommender systems, search engines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ethics: *Can* we use the data?\n",
    "- GDPR,  Privacy policies affect how it is collected\n",
    "- The law is very clear that we have to give people the right to:\n",
    "  - Provide Informed Consent about  how we are going to use their personal data at the time we collect it\n",
    "  - Find out what information we hold about them\n",
    "  - Withdraw their data (e.g. “right to forget”)\n",
    "\n",
    "- Examples of unethical use:    \n",
    " - Cambridge Analytica,   \n",
    " - targeting of fake news, propaganda on social media\n",
    "\n",
    "- Nowadays there should be clear collaboration agreements describing who is the data controller and who is the data processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ethics: *Should* we use the data? <img src=\"figures/ML/algorithms-of-oppression.png\" style=\"float:right\" width = 100> \n",
    "<img style=\"float:right\" src=\"figures/ML/protected-characteristics.png\" width = 600>\n",
    "\n",
    "- ML is only as good as the data we give it\n",
    "- So we have to be very careful that the data is representative\n",
    "\n",
    "- Examples of problems:\n",
    "  - Microsoft's (abandoned) Tay Bot\n",
    "  -     <a href=\"https://aibusiness.com/document.asp?doc_id=767688\">Google to remove gender labels from image recognition tool 25/2/21</a>\n",
    "  - <a href=\"https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/\">Predictive policing algorithms are racist. They need to be dismantled.</a>\n",
    "  -  <a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G\">Amazon scraps secret AI recruiting tool that showed bias against women</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quick Video from Cog-x\n",
    "\n",
    "[![AI Ethics with Dong Nguyen, The Alan Turing Institute | CogX17 Highlight | CogX](https://img.youtube.com/vi/v=M-ko82Y0GUQ/0.jpg)](https://www.youtube.com/watch?v=M-ko82Y0GUQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsupervised Learning <img src=\"figures/ML/clustering.png\" style=\"float:right\" width=400>\n",
    "- Don’t have labels but we still want to find useful groups\n",
    "- All data is defined in terms of values for features\n",
    "  - Numbers,  categories (colour, name, Uni course),  or even just present-absent\n",
    "- So we define distance measure d(a,b) between two data items a and b.\n",
    "  - Hamming Distance (number of features where a and b differ)\n",
    "  - Euclidean (straight line) distance for continuous numbers\n",
    "- Typically in clustering we look for a way of putting the data items into k clusters  \n",
    "  We don't have labels for outputs  \n",
    "  So search for models to maximise *Quality of Clustering*\n",
    "  - intercluster distance (max value of  d(a,b) for all a,b, in the cluster) is minimized\n",
    "  - Intracluster distance (min value of d(a,c) for a and c in different clusters) is maximised\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K Means: probably the best known clustering algorithm\n",
    "\n",
    "Basic Idea:  \n",
    "\n",
    "- clusters defined by a set of *centroids* (mid-points)\n",
    "- data items assigned to the cluster with the closest centroid\n",
    "\n",
    "Algorithm\n",
    "- start with randomly picked items as  centroids\n",
    "- Loop:\n",
    "  - assign items to clusters\n",
    "  -  move each centroids to the new mid-point of all the items in the cluster\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Means : Pseudocode\n",
    "```\n",
    "  Pick K data points at random\n",
    "  Store as  cluster “centroids” C_k k=1,...,K\n",
    "  \n",
    "  Set Converged = False\n",
    "  While Converged= False:  \n",
    "\n",
    "    #Step 1: Assign items to clusters  \n",
    "    For each data point i:  \n",
    "      For each cluster k:\n",
    "        Calculate distance d(i,C_k) \n",
    "      Assign i to nearest cluster\n",
    " \n",
    "    #Step 2: Check to see if there algorithm has converged\n",
    "    If no datapoints have moved cluster:\n",
    "       Converged = True\n",
    "    Else:\n",
    "       Remember new cluster membership\n",
    " \n",
    "    #Step 3 Update cluster centroids\n",
    "    Foreach cluster k in (1...K):\n",
    "      Set new cluster centroid C_k =  mean position of  points in cluster\n",
    "      Update Cluster metrics\n",
    "```\n",
    "    \n",
    " \n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# start by importing some modules we will use\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# importthe apples-ornages-bananas data set from the first week\n",
    "# class labels are 0:apple, 1:orange 2: banana\n",
    "# columns in X are Red,Green,Blue,Width,Height,Weight,Type\n",
    "\n",
    "# read in all thedata fro mthe apples-oranges-banas dataset\n",
    "alldata = np.genfromtxt('data/fruit_values.csv', delimiter=',')\n",
    "\n",
    "#pull out the first two  feature vales and the labels into two differnt arrays\n",
    "X = alldata[:,:2]\n",
    "\n",
    "y= np.genfromtxt('data/fruit_label_ids.csv',delimiter=',')\n",
    "\n",
    "numItems = X.shape[0]\n",
    "\n",
    "numFeatures  = X.shape[1]\n",
    "print(\" The shape of X is {} so there are {} items, each with {} features\".format(X.shape,numItems,numFeatures))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def AssignItemsToClusters(X, centres):\n",
    "    dist = euclidean_distances(X, centres) # dist is an array of size [numItems][K]\n",
    "    labels = np.argmin(dist, axis=1) #newlabels is a 1-D array of size [numItems]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def PlotCluster(X,labels,cents, iteration):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    # show a scatter plot  coloured by labels\n",
    "    fig = plt.scatter(X[:, 0], X[:, 1], c=labels)\n",
    "    for k in range(cents.shape[0]):\n",
    "        plt.plot(cents[k][0],cents[k][1], marker = '*',color='r',markersize=12)\n",
    "    plotTitle= \"Cluster membership and centroids: iteration \" + str(iteration) \n",
    "    title= plt.title(plotTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def runKMEANS(X,centres,  numMoved=1,iteration=0):\n",
    "    while ( iteration < 10 and numMoved>0):\n",
    "        numMoved = 0\n",
    "        numberInCluster = np.zeros(K)\n",
    "\n",
    "        # Step 1: assign items to  clusters\n",
    "        newLabels = AssignItemsToClusters(X,centres) \n",
    "        for i in range(numItems):\n",
    "            if newLabels[i] != clusterLabels[i] : # item has changed. cluster\n",
    "                numMoved = numMoved +1\n",
    "                clusterLabels[i] = newLabels[i]\n",
    "            numberInCluster[ newLabels[i] ] += 1\n",
    "        \n",
    "        #step 2: see if algorithm has converged\n",
    "        if( numMoved==0):\n",
    "            print(\"stopped after {} iterations\".format(iteration))\n",
    "    \n",
    "        #step 3: find new cluster centroids\n",
    "        for k in range(K): # loop through each cluster\n",
    "            newCentroid = np.zeros(numFeatures)\n",
    "            for item in range(numItems):\n",
    "                if (clusterLabels[item]==k) :\n",
    "                    newCentroid += X[item]/numberInCluster[k]\n",
    "            centres[k] = newCentroid\n",
    "        PlotCluster(X,clusterLabels,centres,iteration)  \n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "#  pick randomK starting points as the initial cluster centres\n",
    "idx = np.random.randint(numItems, size=K)\n",
    "centres = X[idx,:]\n",
    "iteration=0\n",
    "clusterLabels = np.ones(numItems)\n",
    "numMoved=100\n",
    "\n",
    "PlotCluster(X,clusterLabels,centres,iteration)\n",
    "\n",
    "runKMEANS(X,centres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Of course you wouldn't normally write your own version...\n",
    "\n",
    "Highly optimised versions available in well-established frameworks e.g. Weka (Java), scikit-learn (python).\n",
    "\n",
    "`class sklearn.cluster.KMeans(n_clusters=8, *, init='k-means++', n_init=10, max_iter=300, tol=0.0001,...)`  \n",
    " - defult number of clusters\n",
    " - variety of \"smart\" initialisation schemes\n",
    " - n_init: number of repeats it does before returning the best\n",
    " \n",
    "Object attributes include: \n",
    "- `cluster_centers` :ndarray of shape (n_clusters, n_features)\n",
    "- `labels`  : ndarray of shape (n_samples,)\n",
    "- `inertia` : float (Sum of squared distances of samples to their closest cluster center.)\n",
    "\n",
    " \n",
    "Methods include: \n",
    "- `fit(X[, y, sample_weight])` : Compute k-means clustering.\n",
    "or this estimator.\n",
    "- `predict(X[, sample_weight])` : Predict the closest cluster each sample in X belongs to.\n",
    "- `fit_predict(X[, y, sample_weight])` : Compute cluster centers and predict cluster index for each sample.\n",
    "- `get_params([deep])` : Get parameters f\n",
    "- `score(X[, y, sample_weight])` : Opposite of the value of X on the K-means objective.\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Means Strengths and weaknesses \n",
    "<img src=\"figures/ML/kmeans_clustering_examples.png\" style=\"float:right\">\n",
    "\n",
    "### PROS: \n",
    "- fast, \n",
    "- lots of implementations\n",
    "\n",
    "### CONS:\n",
    "- need right value of K, \n",
    "- results depend on starting points\n",
    "\n",
    "### Assumptions:\n",
    "- all features are relevant, \n",
    "- data is \"globular\" with respect to the current features\n",
    "\n",
    "### How could we fix the counter-example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reinforcement Learning\n",
    "Five minute video.\n",
    "\n",
    "[![Reinforcement learning for bar-tenders](https://img.youtube.com/vi/v=m2weFARriE8/0.jpg)](https://www.youtube.com/watch?v=m2weFARriE8)\n",
    "https://www.youtube.com/watch?feature=oembed&v=m2weFARriE8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reinforcement Learning <img src=\"figures/ML/RL.png\" style=\"float:right\" width=400>\n",
    "Q learning was best known initial algorithm\n",
    "- Basic idea is that you have a *Reward* table R\n",
    " - which tells you what reward you get if you are in state s and take action a\n",
    " - for a multi-step problem the immediate rewards might be zero for many states  \n",
    "  e.g. finding your way out of a maze, playing tic-tac-toe (noughts and crosses)  \n",
    "  ... \n",
    "- Uses repeated trials to learn a Quality table Q:  \n",
    "  one row for each  state *s*,  one column for each action *a*\n",
    " - Start exploring, and build up a list of what  \n",
    "   states you have been in: *s<sub>1</sub>*, *s<sub>2</sub>)*, ..., *s<sub>t</sub>)*  \n",
    "   actions you have taken: *a<sub>1</sub>*, *a<sub>2</sub>*, ..., *a<sub>t</sub>*\n",
    " - If at time  *t* you get a reward *r*  \n",
    "   then Q[*s<sub>t</sub>*][*a<sub><sub>)*]  is increased by *r*  \n",
    "   and the previous steps get a 'discounted' reward too    \n",
    "    e.g. Q[ *s<sub>t-1</sub>* ][ *a<sub>t-1</sub>* ] is increased by  0.9 * *r*  \n",
    "    ...\n",
    "- Over time the Q table learns the best sequences of moves to take,  \n",
    "   so you can use it to pick the next move\n",
    "    \n",
    "- Problems with scalability as numbers of  \n",
    "  possible states and actions increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Reinforcement Learning  <img src=\"figures/ML/AlphaGoZero.png\" style=\"float:right\" width=200>\n",
    "- neural net rather than table \n",
    "- tends to learn “end-to-end”  rather than a Q table and a policy table\n",
    "  E.g. Alpha Go, Atari simulator\n",
    "- Relies on lots of data:  \n",
    "  e.g. Unity: ‘learning brain’\n",
    "  From ml-agents toolkit\n",
    " Links out to tensorflow model\n",
    " \n",
    "- Alpha Go Zero:   \n",
    "  learned by playing itself!\n",
    "  image from https://medium.com/syncedreview/alphago-zero-approaching-perfection-d8170e2b4e48\n",
    " \n",
    " Really nice explanation of Q-learning here: http://mnemstudio.org/path-finding-q-learning-tutorial.htm\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning\n",
    "Basic idea: Models divide up “decision space” into regions\n",
    "\n",
    "\n",
    "Search for model is driven by minimising error\n",
    "\n",
    "Form depends on what the ouputs can be\n",
    "- Two class:  0/1 loss \n",
    "- Many class: Cross entropy \n",
    "- Continuous: mean squared error\n",
    "\n",
    "Types of models we’ll look at:\n",
    "- K Nearest Neighbours\n",
    "- Greedy Rule Induction\n",
    "- Naïve Bayes\n",
    "- Artificial Neural Nets\n",
    "\n",
    "**Classification** algorithms put labels on regions\n",
    "\n",
    "**Regression** algorithms compute a function in regions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The basic supervised learning process\n",
    "1. Choose features according to what kind of data you have available\n",
    "2. Decide what types of model might be appropriate \n",
    " - human readable?,   \n",
    " - type and amount of data?    \n",
    "3. Initialise Model \n",
    "4.  While not finished:\n",
    "  - See how well it does on training set\n",
    " - Adapt model to reduce error on training set\n",
    "5.  Try to estimate how good it is\n",
    "\n",
    "Often do steps 3-5 above in parallel with different types of model or metaparameters\n",
    "E.g. max number of rules, max depth of trees, value of k in kNN, learning rates in ANN   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How we use our data <img src=\"figures/ML/using_data.png\" style=\"float:right\" width=300>\n",
    "\n",
    "### Unsupervised Learning: \n",
    "- Estimate of quality is based on whole dataset,  \n",
    "  so use it all for training\n",
    "\n",
    "### Reinforcement learning:\n",
    "- Problem is usually lack of data compared to size of state-action space.  \n",
    "- Because data is only generated by using the algorithm!\n",
    "- Alternate periods of:\n",
    "  - training (explore state-action-reward space to improve model)\n",
    "  - testing (choose current max predicted reward in each state) \n",
    "  \n",
    "### Supervised learning:\n",
    "Most commonly work in *off-line* or  *batch* mode \n",
    "- Random split of the data into separate test set, training set, and sometimes validation set\n",
    "- Final model then built using all the data available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary: you need to know and understand\n",
    "- When it is legal and ethical to use data\n",
    "- The basic workflow of **preprocess** &rarr; **train** &rarr; **test**\n",
    "- The difference between **Unsupervised**, **Reinforcement**, and **Supervised Learning**\n",
    "- kMeans as a typical unsupervised clustering algorithm\n",
    "  - stochastic, distance-based\n",
    "- The basic idea (but not the details) of reinforcement learning \n",
    "  - immediate rewards for taking action *a* in state *s*\n",
    "  - build up a Q-table predicting future reward for taking action *a* in state *s*\n",
    "- Supervised learning:\n",
    "  - places *decision boundaries* to divide  feature space into regions\n",
    "  - *Classification*: each region has a label; *Regression*: each region calculates a number\n",
    "  - adapts boundaries to minimise error on the *training set*\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
